{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhonlucas/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('../data/libras_dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>subject</th>\n",
       "      <th>interpretation</th>\n",
       "      <th>example_portuguese_sentence</th>\n",
       "      <th>example_libras_sentence</th>\n",
       "      <th>grammar_class</th>\n",
       "      <th>word_origin</th>\n",
       "      <th>video_link</th>\n",
       "      <th>image_link</th>\n",
       "      <th>hand_image_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>NENHUM</td>\n",
       "      <td>Primeira letra do alfabeto da língua portuguesa; sinal gráfico elementar com que se representam os vocábulos na língua escrita.</td>\n",
       "      <td>Invente qualquer palavra que comece com a letra A.</td>\n",
       "      <td>VOCÊ INVENTAR QUALQUER PALAVRA COMEÇAR A.</td>\n",
       "      <td>SUBSTANTIVO</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/aSm_Prog001.mp4</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/aSm_Prog001.jpg</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABACATE</td>\n",
       "      <td>FRUTA</td>\n",
       "      <td>O fruto do abacateiro. Comestível, tem a polpa amarelada e macia. É consumido puro, com açúcar, em pratos salgados ou em vitaminas.</td>\n",
       "      <td>Você gosta de abacate com leite?</td>\n",
       "      <td>VOCÊ GOSTAR ABACATE LEITE JUNTO?</td>\n",
       "      <td>SUBSTANTIVO</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/abacateSm_Prog001.mp4</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/abacateSm_Prog001.jpg</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg53a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACAXI</td>\n",
       "      <td>FRUTA</td>\n",
       "      <td>Fruta de casca grossa e áspera. Sua polpa pode ser consumida pura, em forma de sucos, doces e sorvetes.</td>\n",
       "      <td>Hoje tomei suco de abacaxi, ele estava ácido.</td>\n",
       "      <td>HOJE S-U-C-O ABACAXI BEBER ÁCID@.</td>\n",
       "      <td>SUBSTANTIVO</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/abacaxiSm_Prog001.mp4</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/abacaxiSm_Prog001.jpg</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg47.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABAFAR</td>\n",
       "      <td>NENHUM</td>\n",
       "      <td>Cobrir ou fechar, para manter o calor.</td>\n",
       "      <td>Se você quer abafar seu quarto, é melhor fechar tudo.</td>\n",
       "      <td>S-I VOCÊ QUERER QUARTO SE@ ABAFAR A-R? MELHOR FECHAR-TUDO.</td>\n",
       "      <td>VERBO</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/abafarSm_Prog001.mp4</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/abafarSm_Prog001.jpg</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg07.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABAIXO</td>\n",
       "      <td>NENHUM</td>\n",
       "      <td>Lugar, posição ou situação inferior, em relação a outros de nível mais elevado.</td>\n",
       "      <td>Não é no primeiro apartamento abaixo, é no segundo.</td>\n",
       "      <td>APARTAMENTO PRIMEIR@ NÃO SEGUND@ ABAIXO.</td>\n",
       "      <td>ADV.</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/abaixoSm_Prog001.mp4</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/abaixoSm_Prog001.jpg</td>\n",
       "      <td>https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg62.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word subject  \\\n",
       "0        A  NENHUM   \n",
       "1  ABACATE   FRUTA   \n",
       "2  ABACAXI   FRUTA   \n",
       "3   ABAFAR  NENHUM   \n",
       "4   ABAIXO  NENHUM   \n",
       "\n",
       "                                                                                                                        interpretation  \\\n",
       "0      Primeira letra do alfabeto da língua portuguesa; sinal gráfico elementar com que se representam os vocábulos na língua escrita.   \n",
       "1  O fruto do abacateiro. Comestível, tem a polpa amarelada e macia. É consumido puro, com açúcar, em pratos salgados ou em vitaminas.   \n",
       "2                              Fruta de casca grossa e áspera. Sua polpa pode ser consumida pura, em forma de sucos, doces e sorvetes.   \n",
       "3                                                                                               Cobrir ou fechar, para manter o calor.   \n",
       "4                                                      Lugar, posição ou situação inferior, em relação a outros de nível mais elevado.   \n",
       "\n",
       "                             example_portuguese_sentence  \\\n",
       "0     Invente qualquer palavra que comece com a letra A.   \n",
       "1                       Você gosta de abacate com leite?   \n",
       "2          Hoje tomei suco de abacaxi, ele estava ácido.   \n",
       "3  Se você quer abafar seu quarto, é melhor fechar tudo.   \n",
       "4    Não é no primeiro apartamento abaixo, é no segundo.   \n",
       "\n",
       "                                      example_libras_sentence grammar_class  \\\n",
       "0                   VOCÊ INVENTAR QUALQUER PALAVRA COMEÇAR A.   SUBSTANTIVO   \n",
       "1                            VOCÊ GOSTAR ABACATE LEITE JUNTO?   SUBSTANTIVO   \n",
       "2                           HOJE S-U-C-O ABACAXI BEBER ÁCID@.   SUBSTANTIVO   \n",
       "3  S-I VOCÊ QUERER QUARTO SE@ ABAFAR A-R? MELHOR FECHAR-TUDO.         VERBO   \n",
       "4                    APARTAMENTO PRIMEIR@ NÃO SEGUND@ ABAIXO.          ADV.   \n",
       "\n",
       "  word_origin  \\\n",
       "0    Nacional   \n",
       "1    Nacional   \n",
       "2    Nacional   \n",
       "3    Nacional   \n",
       "4    Nacional   \n",
       "\n",
       "                                                                                        video_link  \\\n",
       "0        https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/aSm_Prog001.mp4   \n",
       "1  https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/abacateSm_Prog001.mp4   \n",
       "2  https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/abacaxiSm_Prog001.mp4   \n",
       "3   https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/abafarSm_Prog001.mp4   \n",
       "4   https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/videos/abaixoSm_Prog001.mp4   \n",
       "\n",
       "                                                                                        image_link  \\\n",
       "0        https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/aSm_Prog001.jpg   \n",
       "1  https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/abacateSm_Prog001.jpg   \n",
       "2  https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/abacaxiSm_Prog001.jpg   \n",
       "3   https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/abafarSm_Prog001.jpg   \n",
       "4   https://www.ines.gov.br/dicionario-de-libras/public/media/palavras/images/abaixoSm_Prog001.jpg   \n",
       "\n",
       "                                                           hand_image_link  \n",
       "0   https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg01.jpg  \n",
       "1  https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg53a.jpg  \n",
       "2   https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg47.jpg  \n",
       "3   https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg07.jpg  \n",
       "4   https://www.ines.gov.br/dicionario-de-libras/public/media/mao/cg62.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 5 rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_portuguese_sentence</th>\n",
       "      <th>example_libras_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Invente qualquer palavra que comece com a letra A.</td>\n",
       "      <td>VOCÊ INVENTAR QUALQUER PALAVRA COMEÇAR A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Você gosta de abacate com leite?</td>\n",
       "      <td>VOCÊ GOSTAR ABACATE LEITE JUNTO?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoje tomei suco de abacaxi, ele estava ácido.</td>\n",
       "      <td>HOJE S-U-C-O ABACAXI BEBER ÁCID@.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Se você quer abafar seu quarto, é melhor fechar tudo.</td>\n",
       "      <td>S-I VOCÊ QUERER QUARTO SE@ ABAFAR A-R? MELHOR FECHAR-TUDO.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não é no primeiro apartamento abaixo, é no segundo.</td>\n",
       "      <td>APARTAMENTO PRIMEIR@ NÃO SEGUND@ ABAIXO.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             example_portuguese_sentence  \\\n",
       "0     Invente qualquer palavra que comece com a letra A.   \n",
       "1                       Você gosta de abacate com leite?   \n",
       "2          Hoje tomei suco de abacaxi, ele estava ácido.   \n",
       "3  Se você quer abafar seu quarto, é melhor fechar tudo.   \n",
       "4    Não é no primeiro apartamento abaixo, é no segundo.   \n",
       "\n",
       "                                      example_libras_sentence  \n",
       "0                   VOCÊ INVENTAR QUALQUER PALAVRA COMEÇAR A.  \n",
       "1                            VOCÊ GOSTAR ABACATE LEITE JUNTO?  \n",
       "2                           HOJE S-U-C-O ABACAXI BEBER ÁCID@.  \n",
       "3  S-I VOCÊ QUERER QUARTO SE@ ABAFAR A-R? MELHOR FECHAR-TUDO.  \n",
       "4                    APARTAMENTO PRIMEIR@ NÃO SEGUND@ ABAIXO.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['example_portuguese_sentence', 'example_libras_sentence']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove characters that are not letters from the sentences in Libras\n",
    "data['example_libras_sentence'] = data['example_libras_sentence'].str.replace(\"@\", \"o\")\n",
    "data['example_libras_sentence'] = data['example_libras_sentence'].str.replace(\"-\", \"\")\n",
    "data['example_libras_sentence'] = data['example_libras_sentence'].str.lower()\n",
    "data['example_portuguese_sentence'] = data['example_portuguese_sentence'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_portuguese_sentence</th>\n",
       "      <th>example_libras_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invente qualquer palavra que comece com a letra a.</td>\n",
       "      <td>você inventar qualquer palavra começar a.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>você gosta de abacate com leite?</td>\n",
       "      <td>você gostar abacate leite junto?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hoje tomei suco de abacaxi, ele estava ácido.</td>\n",
       "      <td>hoje suco abacaxi beber ácido.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>se você quer abafar seu quarto, é melhor fechar tudo.</td>\n",
       "      <td>si você querer quarto seo abafar ar? melhor fechartudo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>não é no primeiro apartamento abaixo, é no segundo.</td>\n",
       "      <td>apartamento primeiro não segundo abaixo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>os surdos fizeram um abaixo-assinado pedindo mais empregos ao governo.</td>\n",
       "      <td>surdo abaixoassinado pedir governo emprego mais.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a lâmpada do abajur queimou.</td>\n",
       "      <td>coisacônicalâmpada lâmpadaqueimar .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>está vendo aquela velha se abanando? ela é avó da minha amiga.</td>\n",
       "      <td>2solhar3s velho abanarleque lá(me) vovo amigo(md).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>o carro velho foi abandonado naquela garagem.</td>\n",
       "      <td>aquelo caragem carro velho abandonar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coitada dessa criança tão bonita dormindo na rua. como seus pais tiveram coragem de abandoná-la?!</td>\n",
       "      <td>criança bonito dormir rua coitado! pai mãe delo abandonar coragem?!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         example_portuguese_sentence  \\\n",
       "0                                                 invente qualquer palavra que comece com a letra a.   \n",
       "1                                                                   você gosta de abacate com leite?   \n",
       "2                                                      hoje tomei suco de abacaxi, ele estava ácido.   \n",
       "3                                              se você quer abafar seu quarto, é melhor fechar tudo.   \n",
       "4                                                não é no primeiro apartamento abaixo, é no segundo.   \n",
       "5                             os surdos fizeram um abaixo-assinado pedindo mais empregos ao governo.   \n",
       "6                                                                       a lâmpada do abajur queimou.   \n",
       "7                                     está vendo aquela velha se abanando? ela é avó da minha amiga.   \n",
       "8                                                      o carro velho foi abandonado naquela garagem.   \n",
       "9  coitada dessa criança tão bonita dormindo na rua. como seus pais tiveram coragem de abandoná-la?!   \n",
       "\n",
       "                                               example_libras_sentence  \n",
       "0                            você inventar qualquer palavra começar a.  \n",
       "1                                     você gostar abacate leite junto?  \n",
       "2                                       hoje suco abacaxi beber ácido.  \n",
       "3              si você querer quarto seo abafar ar? melhor fechartudo.  \n",
       "4                             apartamento primeiro não segundo abaixo.  \n",
       "5                     surdo abaixoassinado pedir governo emprego mais.  \n",
       "6                                  coisacônicalâmpada lâmpadaqueimar .  \n",
       "7                   2solhar3s velho abanarleque lá(me) vovo amigo(md).  \n",
       "8                                aquelo caragem carro velho abandonar.  \n",
       "9  criança bonito dormir rua coitado! pai mãe delo abandonar coragem?!  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['example_portuguese_sentence', 'example_libras_sentence']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['example_portuguese_sentence', 'example_libras_sentence']].to_csv('../data/libras_dictionary_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with manual corrections\n",
    "data_cleaned = pd.read_csv('../data/libras_dictionary_cleaned_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_portuguese_sentence</th>\n",
       "      <th>example_libras_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invente qualquer palavra que comece com a letra a.</td>\n",
       "      <td>você inventar qualquer palavra começar a.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>você gosta de abacate com leite?</td>\n",
       "      <td>você gostar abacate leite junto?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hoje tomei suco de abacaxi, ele estava ácido.</td>\n",
       "      <td>hoje suco abacaxi beber ácido.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>se você quer abafar seu quarto, é melhor fechar tudo.</td>\n",
       "      <td>si você querer quarto seu abafar ar? melhor fechar tudo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>não é no primeiro apartamento abaixo, é no segundo.</td>\n",
       "      <td>apartamento primeiro não segundo abaixo.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             example_portuguese_sentence  \\\n",
       "0     invente qualquer palavra que comece com a letra a.   \n",
       "1                       você gosta de abacate com leite?   \n",
       "2          hoje tomei suco de abacaxi, ele estava ácido.   \n",
       "3  se você quer abafar seu quarto, é melhor fechar tudo.   \n",
       "4    não é no primeiro apartamento abaixo, é no segundo.   \n",
       "\n",
       "                                    example_libras_sentence  \n",
       "0                 você inventar qualquer palavra começar a.  \n",
       "1                          você gostar abacate leite junto?  \n",
       "2                            hoje suco abacaxi beber ácido.  \n",
       "3  si você querer quarto seu abafar ar? melhor fechar tudo.  \n",
       "4                  apartamento primeiro não segundo abaixo.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optmi\n",
    "\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import random\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from pprint import pprint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer  # Or BertTokenizer\n",
    "from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n",
    "from transformers import AutoModel  # or BertModel, for BERT without pretraining heads\n",
    "from torch.nn import (TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer)\n",
    "import spacy\n",
    "\n",
    "# Seeding for reproducible results everytime\n",
    "SEED = 777\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert = AutoModelForPreTraining.from_pretrained('neuralmind/bert-large-portuguese-cased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-large-portuguese-cased', do_lower_case=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Preprocessing\n",
    "\n",
    "Let's see some of the process it can do,\n",
    "\n",
    "* Train/ Valid/ Test Split: partition your data into a specified train/ valid/ test set.\n",
    "\n",
    "* File Loading: load the text corpus of various formats (.txt,.json,.csv).\n",
    "\n",
    "* Tokenization: breaking sentences into list of words.\n",
    "\n",
    "* Vocab: Generate a list of vocabulary from the text corpus.\n",
    "\n",
    "* Words to Integer Mapper: Map words into integer numbers for the entire corpus and vice versa.\n",
    "\n",
    "* Word Vector: Convert a word from higher dimension to lower dimension (Word Embedding).\n",
    "\n",
    "* Batching: Generate batches of sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy portuguese tokenizer\n",
    "spacy_pt = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(text):\n",
    "    return [tok.text for tok in spacy_pt.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "libras_sentences_source = Field(\n",
    "    tokenize = spacy_tokenizer,\n",
    "    lower=True,\n",
    "    init_token=\"\",\n",
    "    eos_token=\"\",\n",
    ")\n",
    "\n",
    "portuguese_sentences_target = Field(\n",
    "    tokenize = spacy_tokenizer,\n",
    "    lower=True,\n",
    "    init_token=\"\",\n",
    "    eos_token=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TabularDataset(path='../data/libras_dictionary_cleaned_sample.csv', format='csv', fields=[('trg', portuguese_sentences_target), ('src', libras_sentences_source)], skip_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = dataset.split(split_ratio=[0.8, 0.1, 0.1], random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 800\n",
      "Number of validation examples: 100\n",
      "Number of testing examples: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(val_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain sentence example - Libras  ['ir', 'apostar', '?', 'quem', 'primeiro', 'alcançar', 'árvore', 'aquele', 'bala', 'ganhar', '.']\n",
      "Tain sentence example - Portuguese  ['vamos', 'apostar', '?', 'ganha', 'uma', 'bala', 'quem', 'alcançar', 'primeiro', 'aquela', 'árvore', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tain sentence example - Libras \", train_data.examples[0].src)\n",
    "print(\"Tain sentence example - Portuguese \", train_data.examples[0].trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "libras_sentences_source.build_vocab(train_data, min_freq=2)\n",
    "portuguese_sentences_target.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (libras) vocabulary: 651\n",
      "Unique tokens in target (portuguse) vocabulary: 685\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (libras) vocabulary: {len(libras_sentences_source.vocab)}\")\n",
    "print(f\"Unique tokens in target (portuguse) vocabulary: {len(portuguese_sentences_target.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128])\n",
      "torch.Size([17, 128])\n",
      "torch.Size([13, 128])\n",
      "torch.Size([21, 128])\n",
      "torch.Size([10, 128])\n",
      "torch.Size([20, 128])\n",
      "torch.Size([9, 128])\n",
      "torch.Size([19, 128])\n",
      "torch.Size([7, 128])\n",
      "torch.Size([14, 128])\n",
      "torch.Size([18, 32])\n",
      "torch.Size([25, 32])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch.src.shape)\n",
    "    print(batch.trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(libras_sentences_source.vocab)\n",
    "OUTPUT_DIM = len(portuguese_sentences_target.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(651, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(685, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=685, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 8,049,837 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optmi.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = portuguese_sentences_target.vocab.stoi[portuguese_sentences_target.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 0s\n",
      "\tTrain Loss: 5.682 | Train PPL: 293.681\n",
      "\t Val. Loss: 4.575 |  Val. PPL:  97.018\n",
      "Epoch: 02 | Time: 0m 0s\n",
      "\tTrain Loss: 4.613 | Train PPL: 100.825\n",
      "\t Val. Loss: 4.162 |  Val. PPL:  64.227\n",
      "Epoch: 03 | Time: 0m 0s\n",
      "\tTrain Loss: 4.458 | Train PPL:  86.346\n",
      "\t Val. Loss: 4.162 |  Val. PPL:  64.176\n",
      "Epoch: 04 | Time: 0m 0s\n",
      "\tTrain Loss: 4.324 | Train PPL:  75.489\n",
      "\t Val. Loss: 4.079 |  Val. PPL:  59.102\n",
      "Epoch: 05 | Time: 0m 0s\n",
      "\tTrain Loss: 4.271 | Train PPL:  71.568\n",
      "\t Val. Loss: 4.191 |  Val. PPL:  66.107\n",
      "Epoch: 06 | Time: 0m 0s\n",
      "\tTrain Loss: 4.254 | Train PPL:  70.406\n",
      "\t Val. Loss: 4.036 |  Val. PPL:  56.613\n",
      "Epoch: 07 | Time: 0m 0s\n",
      "\tTrain Loss: 4.222 | Train PPL:  68.155\n",
      "\t Val. Loss: 4.154 |  Val. PPL:  63.718\n",
      "Epoch: 08 | Time: 0m 0s\n",
      "\tTrain Loss: 4.224 | Train PPL:  68.315\n",
      "\t Val. Loss: 4.052 |  Val. PPL:  57.538\n",
      "Epoch: 09 | Time: 0m 0s\n",
      "\tTrain Loss: 4.203 | Train PPL:  66.878\n",
      "\t Val. Loss: 4.135 |  Val. PPL:  62.464\n",
      "Epoch: 10 | Time: 0m 0s\n",
      "\tTrain Loss: 4.188 | Train PPL:  65.900\n",
      "\t Val. Loss: 4.120 |  Val. PPL:  61.584\n",
      "Epoch: 11 | Time: 0m 0s\n",
      "\tTrain Loss: 4.133 | Train PPL:  62.384\n",
      "\t Val. Loss: 4.140 |  Val. PPL:  62.821\n",
      "Epoch: 12 | Time: 0m 0s\n",
      "\tTrain Loss: 4.111 | Train PPL:  61.028\n",
      "\t Val. Loss: 4.140 |  Val. PPL:  62.790\n",
      "Epoch: 13 | Time: 0m 0s\n",
      "\tTrain Loss: 4.076 | Train PPL:  58.918\n",
      "\t Val. Loss: 4.209 |  Val. PPL:  67.308\n",
      "Epoch: 14 | Time: 0m 0s\n",
      "\tTrain Loss: 4.027 | Train PPL:  56.085\n",
      "\t Val. Loss: 4.169 |  Val. PPL:  64.674\n",
      "Epoch: 15 | Time: 0m 0s\n",
      "\tTrain Loss: 4.017 | Train PPL:  55.561\n",
      "\t Val. Loss: 4.238 |  Val. PPL:  69.279\n",
      "Epoch: 16 | Time: 0m 0s\n",
      "\tTrain Loss: 3.970 | Train PPL:  52.997\n",
      "\t Val. Loss: 4.227 |  Val. PPL:  68.488\n",
      "Epoch: 17 | Time: 0m 0s\n",
      "\tTrain Loss: 3.948 | Train PPL:  51.847\n",
      "\t Val. Loss: 4.225 |  Val. PPL:  68.364\n",
      "Epoch: 18 | Time: 0m 0s\n",
      "\tTrain Loss: 3.908 | Train PPL:  49.809\n",
      "\t Val. Loss: 4.229 |  Val. PPL:  68.672\n",
      "Epoch: 19 | Time: 0m 0s\n",
      "\tTrain Loss: 3.904 | Train PPL:  49.613\n",
      "\t Val. Loss: 4.181 |  Val. PPL:  65.436\n",
      "Epoch: 20 | Time: 0m 0s\n",
      "\tTrain Loss: 3.902 | Train PPL:  49.481\n",
      "\t Val. Loss: 4.310 |  Val. PPL:  74.434\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'slt_libras.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('slt_libras.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8744261264801025"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.874 | Test PPL:  48.155 |\n"
     ]
    }
   ],
   "source": [
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, libras, portuguese, device, max_length=50):\n",
    "\n",
    "    if type(sentence) == str:\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    tokens.insert(0, libras.init_token)\n",
    "    tokens.append(libras.eos_token)\n",
    "    text_to_indices = [libras.vocab.stoi[token] for token in tokens]\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.bert.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [portuguese.vocab.stoi[\"\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.bert.decoder(previous_word, hidden, cell)\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == portuguese.vocab.stoi[\"\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [portuguese.vocab.itos[idx] for idx in outputs]\n",
    "    return translated_sentence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert = model_bert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence:  ['ele', 'atenção', 'palestra', '.']\n",
      "Correct translation:  ['ele', 'está', 'com', 'a', 'atenção', 'voltada', 'para', 'a', 'palestra', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Test sentence: \", test_data[1].src)\n",
    "print(\"Correct translation: \", test_data[1].trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = [\"ele atenção palestra.\"]\n",
    "correct_sentence = [\"ele está com a atenção voltada para a palestra.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTranslated sentence: \u001b[39m\u001b[39m\"\u001b[39m, translate_sentence(model_bert, test_sentence, libras_sentences_source, portuguese_sentences_target, device))\n",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m, in \u001b[0;36mtranslate_sentence\u001b[0;34m(model, sentence, libras, portuguese, device, max_length)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Build encoder hidden, cell state\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 14\u001b[0m     hidden, cell \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mbert\u001b[39m.\u001b[39;49mencoder(sentence_tensor)\n\u001b[1;32m     16\u001b[0m outputs \u001b[39m=\u001b[39m [portuguese\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mstoi[\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_length):\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    603\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    611\u001b[0m         hidden_states,\n\u001b[1;32m    612\u001b[0m         attention_mask,\n\u001b[1;32m    613\u001b[0m         layer_head_mask,\n\u001b[1;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    616\u001b[0m         past_key_value,\n\u001b[1;32m    617\u001b[0m         output_attentions,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:496\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    485\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    486\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    493\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    494\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    495\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 496\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    497\u001b[0m         hidden_states,\n\u001b[1;32m    498\u001b[0m         attention_mask,\n\u001b[1;32m    499\u001b[0m         head_mask,\n\u001b[1;32m    500\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    501\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    502\u001b[0m     )\n\u001b[1;32m    503\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    505\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:426\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    417\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    418\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    425\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 426\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    427\u001b[0m         hidden_states,\n\u001b[1;32m    428\u001b[0m         attention_mask,\n\u001b[1;32m    429\u001b[0m         head_mask,\n\u001b[1;32m    430\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    431\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    432\u001b[0m         past_key_value,\n\u001b[1;32m    433\u001b[0m         output_attentions,\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    436\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:285\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    284\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 285\u001b[0m     mixed_query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery(hidden_states)\n\u001b[1;32m    287\u001b[0m     \u001b[39m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[39m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[39m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     is_cross_attention \u001b[39m=\u001b[39m encoder_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/projects/translation-libras-to-ptbr/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "print(\"Translated sentence: \", translate_sentence(model_bert, test_sentence, libras_sentences_source, portuguese_sentences_target, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448d780881a940d49ab191b2d1b463a8c02ae47a3b8017bde1517a5fe99f211"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
